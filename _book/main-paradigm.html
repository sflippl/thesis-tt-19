<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>thesis-tt-19.utf8.md</title>
  <meta name="description" content="This dissertation has been submitted in Trinity Term 2019 as part of the MSc Neuroscience.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="thesis-tt-19.utf8.md" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This dissertation has been submitted in Trinity Term 2019 as part of the MSc Neuroscience." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="thesis-tt-19.utf8.md" />
  
  <meta name="twitter:description" content="This dissertation has been submitted in Trinity Term 2019 as part of the MSc Neuroscience." />
  

<meta name="author" content="Samuel Lippl">


<meta name="date" content="2019-08-07">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="methods.html">
<link rel="next" href="behavioral-paradigm.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Creating Novel Sensorimotor Responses in Auditory Cortex</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2</b> Methods</a><ul>
<li class="chapter" data-level="2.1" data-path="main-paradigm.html"><a href="main-paradigm.html"><i class="fa fa-check"></i><b>2.1</b> Main Paradigm</a></li>
<li class="chapter" data-level="2.2" data-path="behavioral-paradigm.html"><a href="behavioral-paradigm.html"><i class="fa fa-check"></i><b>2.2</b> Behavioral Paradigm</a><ul>
<li class="chapter" data-level="2.2.1" data-path="behavioral-paradigm.html"><a href="behavioral-paradigm.html#the-acquisition-question-strategy-perturbations"><i class="fa fa-check"></i><b>2.2.1</b> The Acquisition Question: Strategy Perturbations</a></li>
<li class="chapter" data-level="2.2.2" data-path="behavioral-paradigm.html"><a href="behavioral-paradigm.html#the-representation-question-sensorimotor-and-reward-perturbations"><i class="fa fa-check"></i><b>2.2.2</b> The Representation Question: Sensorimotor and Reward Perturbations</a></li>
<li class="chapter" data-level="2.2.3" data-path="behavioral-paradigm.html"><a href="behavioral-paradigm.html#the-integration-question-level-modulations"><i class="fa fa-check"></i><b>2.2.3</b> The Integration Question: Level Modulations</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="data-analysis.html"><a href="data-analysis.html"><i class="fa fa-check"></i><b>2.3</b> Data Analysis</a><ul>
<li class="chapter" data-level="2.3.1" data-path="data-analysis.html"><a href="data-analysis.html#event-based-analysis"><i class="fa fa-check"></i><b>2.3.1</b> Event-based analysis</a></li>
<li class="chapter" data-level="2.3.2" data-path="data-analysis.html"><a href="data-analysis.html#behavioral-analysis"><i class="fa fa-check"></i><b>2.3.2</b> Behavioral Analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>3</b> Results</a><ul>
<li class="chapter" data-level="3.1" data-path="acquisition.html"><a href="acquisition.html"><i class="fa fa-check"></i><b>3.1</b> Acquisition</a><ul>
<li class="chapter" data-level="3.1.1" data-path="acquisition.html"><a href="acquisition.html#distinguishing-a-sound-driven-strategy-from-learned-motor-patterns"><i class="fa fa-check"></i><b>3.1.1</b> Distinguishing a sound-driven strategy from learned motor patterns</a></li>
<li class="chapter" data-level="3.1.2" data-path="acquisition.html"><a href="acquisition.html#quantifying-behavioral-adaptation"><i class="fa fa-check"></i><b>3.1.2</b> Quantifying behavioral adaptation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>4</b> Discussion</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="toneworld.html"><a href="toneworld.html"><i class="fa fa-check"></i><b>A</b> Toneworld</a><ul>
<li class="chapter" data-level="A.1" data-path="behavioral-data.html"><a href="behavioral-data.html"><i class="fa fa-check"></i><b>A.1</b> Behavioral data</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="main-paradigm" class="section level2">
<h2><span class="header-section-number">2.1</span> Main Paradigm</h2>
<p>Eleven transgenic mice expressing Ai95D-CaMP6f x CaMK2a-Cre in three batches, a male one (GTMK44.3a-c) and two female ones (GTMK44.3e-h; GTMK44.4d-g), were water-restricted and trained on the task. They navigated the tonespace by transversing across six tones per octave. In the beginning, the task was restricted to one octave. As they began adopting sensible behavior, the paradigm was switched to two and then three octaves. The middle tone had a frequency of 11.3 kHz (sound ID: 0) and the other tones were logarithmically placed around it. In the case of one (two; three) octave, there were three (six; nine) tones to each side of the middle sound. The mice were rewarded for sound IDs between -1 and 1 on the side on which they had last licked. Examples for behavioral sequences can be found in figure <a href="data-analysis.html#fig:event-examples">2.1</a>. Each task block lasted for about 10 mins and several of these blocks were acquired per animal per day.</p>
<p>The first two batches were pretrained in behavioral boxes using Python <span class="citation">(Rossum, <a href="#ref-python">1995</a>)</span> and a Raspberry Pi to control the task paradigm. This purpose required the packages ‘numpy’ <span class="citation">(Oliphant, <a href="#ref-oliphant2006numpy">2006</a>; Walt et al., <a href="#ref-vanderwalt2011numpy">2011</a>)</span>, ‘random’, ‘time’, ‘multiprocessing’, ‘RPi.GPIO’, ‘csv’, ‘requests’, ‘pygame’, and ‘sys’. The mice were subsequently moved to the setup under the microscope, which was controlled using Matlab (© Mathworks) and Psychtoolbox <span class="citation">(Brainard, <a href="#ref-brainard1997psychtoolbox">1997</a>; Pelli, <a href="#ref-pelli1997psychtoolbox">1997</a>; Kleiner et al., <a href="#ref-kleiner2007psychtoolbox">2007</a>)</span>. The second female batch (i. e. GTMK44.4d-g) was trained under the microscope from the beginning.</p>
<p>Each sound was presented for 200 ms, with stimulus onset being 500 ms apart. Throughout these 500 ms, the number of left licks <span class="math inline">\(n_l\)</span> and the number of right licks <span class="math inline">\(n_r\)</span> was detected using an electrical lick-detection circuit as described by <span class="citation">Slotnick (<a href="#ref-slotnick2009lick">2009</a>)</span> that was connected to the Raspberry Pi in the behavioral boxes and an NI board under the microscope. The sound ID then changed according to the formula</p>
<p><span class="math display">\[\begin{equation*}
\Delta_{\text{RL}}=2\cdot\left(\log(n_l+1)-\log(n_r+1)\right), \quad 
\Delta_{\text{LR}}=2\cdot\left(\log(n_r+1)-\log(n_l+1)\right),
\end{equation*}\]</span></p>
<p>where the change was rounded to the nearest integer and the resulting sound ID was capped off according to the number of octaves. <span class="math inline">\(\Delta_{\text{RL}}\)</span> was used in the case of the RL-contingency and <span class="math inline">\(\Delta_{\text{LR}}\)</span> was used in the case of the LR-contingency.</p>
<p>While the mice were under the microscope setup, activity in the auditory cortex was recorded using 2-photon imaging through a cranial window. At first, the approximate locations of Primary (A1) and Secondary Auditory Cortex (A2) as well as the Anterior Auditory Field (AAF) were determined. Throughout different days, these areas were then recorded during the task. The microscope was controlled using ScanImage <span class="citation">(Pologruto et al., <a href="#ref-scanimage">2003</a>)</span>. Neural data was acquired from ten mice. GTMK44.3f could not be imaged due to a malformed headbar.</p>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-python">
<p>Rossum G (1995) Python reference manual.</p>
</div>
<div id="ref-oliphant2006numpy">
<p>Oliphant TE (2006) Guide to NumPy. Available at: <a href="http://scholar.google.com/scholar?hl=en{\&amp;}btnG=Search{\&amp;}q=intitle:Guide+to+NumPy{\#}0">http://scholar.google.com/scholar?hl=en{\&amp;}btnG=Search{\&amp;}q=intitle:Guide+to+NumPy{\#}0</a>.</p>
</div>
<div id="ref-vanderwalt2011numpy">
<p>Walt S van der, Colbert SC, Varoquaux G (2011) The NumPy Array: A Structure for Efficient Numerical Computation. Computing in Science &amp; Engineering 13:22–30 Available at: <a href="http://ieeexplore.ieee.org/document/5725236/">http://ieeexplore.ieee.org/document/5725236/</a>.</p>
</div>
<div id="ref-brainard1997psychtoolbox">
<p>Brainard DH (1997) The Psychophysics Toolbox. Spatial Vision 10:433–436.</p>
</div>
<div id="ref-pelli1997psychtoolbox">
<p>Pelli DG (1997) The VideoToolbox software for visual psychophysics: Transforming numbers into movies. Spatial Vision 10:437–442.</p>
</div>
<div id="ref-kleiner2007psychtoolbox">
<p>Kleiner M, Brainard DH, Pelli DG (2007) &quot;What’s new in Psychtoolbox-3?&quot;. Perception 36.</p>
</div>
<div id="ref-slotnick2009lick">
<p>Slotnick B (2009) A Simple 2-Transistor Touch or Lick Detector Circuit. Journal of the Experimental Analysis of Behavior 91:253–255.</p>
</div>
<div id="ref-scanimage">
<p>Pologruto TA, Sabatini BL, Svoboda K (2003) ScanImage: Flexible software for operating laser scanning microscopes. BioMedical Engineering OnLine 2:13 Available at: <a href="http://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-2-13">http://biomedical-engineering-online.biomedcentral.com/articles/10.1186/1475-925X-2-13</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="methods.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="behavioral-paradigm.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["thesis-tt-19.pdf", "thesis-tt-19.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
