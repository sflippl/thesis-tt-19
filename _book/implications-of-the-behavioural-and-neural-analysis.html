<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>thesis-tt-19.utf8.md</title>
  <meta name="description" content="This dissertation has been submitted in Trinity Term 2019 as part of the MSc Neuroscience.">
  <meta name="generator" content="bookdown 0.7 and GitBook 2.6.7">

  <meta property="og:title" content="thesis-tt-19.utf8.md" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This dissertation has been submitted in Trinity Term 2019 as part of the MSc Neuroscience." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="thesis-tt-19.utf8.md" />
  
  <meta name="twitter:description" content="This dissertation has been submitted in Trinity Term 2019 as part of the MSc Neuroscience." />
  

<meta name="author" content="Samuel Lippl">


<meta name="date" content="2019-08-14">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="auditory-cortex-represents-the-artificial-sensorimotor-contingency.html">
<link rel="next" href="references.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Creating Novel Sensorimotor Responses in Auditory Cortex</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Abstract</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2</b> Methods</a><ul>
<li class="chapter" data-level="2.1" data-path="animals.html"><a href="animals.html"><i class="fa fa-check"></i><b>2.1</b> Animals</a><ul>
<li class="chapter" data-level="2.1.1" data-path="animals.html"><a href="animals.html#strain"><i class="fa fa-check"></i><b>2.1.1</b> Strain</a></li>
<li class="chapter" data-level="2.1.2" data-path="animals.html"><a href="animals.html#surgeries"><i class="fa fa-check"></i><b>2.1.2</b> Surgeries</a></li>
<li class="chapter" data-level="2.1.3" data-path="animals.html"><a href="animals.html#preparations-for-behavioural-training"><i class="fa fa-check"></i><b>2.1.3</b> Preparations for behavioural training</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="materials.html"><a href="materials.html"><i class="fa fa-check"></i><b>2.2</b> Materials</a><ul>
<li class="chapter" data-level="2.2.1" data-path="materials.html"><a href="materials.html#behavioural-setup"><i class="fa fa-check"></i><b>2.2.1</b> Behavioural setup</a></li>
<li class="chapter" data-level="2.2.2" data-path="materials.html"><a href="materials.html#two-photon-imaging-setup"><i class="fa fa-check"></i><b>2.2.2</b> Two-photon imaging setup</a></li>
<li class="chapter" data-level="2.2.3" data-path="materials.html"><a href="materials.html#widefield-imaging-setup"><i class="fa fa-check"></i><b>2.2.3</b> Widefield imaging setup</a></li>
<li class="chapter" data-level="2.2.4" data-path="materials.html"><a href="materials.html#imaging-procedures"><i class="fa fa-check"></i><b>2.2.4</b> Imaging procedures</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="behavioural-paradigm.html"><a href="behavioural-paradigm.html"><i class="fa fa-check"></i><b>2.3</b> Behavioural paradigm</a><ul>
<li class="chapter" data-level="2.3.1" data-path="behavioural-paradigm.html"><a href="behavioural-paradigm.html#sensorimotor-task"><i class="fa fa-check"></i><b>2.3.1</b> Sensorimotor task</a></li>
<li class="chapter" data-level="2.3.2" data-path="behavioural-paradigm.html"><a href="behavioural-paradigm.html#violations-of-the-contingency"><i class="fa fa-check"></i><b>2.3.2</b> Violations of the Contingency</a></li>
<li class="chapter" data-level="2.3.3" data-path="behavioural-paradigm.html"><a href="behavioural-paradigm.html#sound-level-modulations"><i class="fa fa-check"></i><b>2.3.3</b> Sound level modulations</a></li>
<li class="chapter" data-level="2.3.4" data-path="behavioural-paradigm.html"><a href="behavioural-paradigm.html#training-methods"><i class="fa fa-check"></i><b>2.3.4</b> Training Methods</a></li>
<li class="chapter" data-level="2.3.5" data-path="behavioural-paradigm.html"><a href="behavioural-paradigm.html#imaging-procedures-1"><i class="fa fa-check"></i><b>2.3.5</b> Imaging procedures</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="reproducibility.html"><a href="reproducibility.html"><i class="fa fa-check"></i><b>2.4</b> Reproducibility</a></li>
<li class="chapter" data-level="2.5" data-path="behavioural-analysis.html"><a href="behavioural-analysis.html"><i class="fa fa-check"></i><b>2.5</b> Behavioural analysis</a></li>
<li class="chapter" data-level="2.6" data-path="neural-analysis.html"><a href="neural-analysis.html"><i class="fa fa-check"></i><b>2.6</b> Neural Analysis</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>3</b> Results</a><ul>
<li class="chapter" data-level="3.1" data-path="acquisition.html"><a href="acquisition.html"><i class="fa fa-check"></i><b>3.1</b> Acquisition</a><ul>
<li class="chapter" data-level="3.1.1" data-path="acquisition.html"><a href="acquisition.html#distinguishing-a-sound-driven-policy-from-a-motor-driven-policy"><i class="fa fa-check"></i><b>3.1.1</b> Distinguishing a sound-driven policy from a motor-driven policy</a></li>
<li class="chapter" data-level="3.1.2" data-path="acquisition.html"><a href="acquisition.html#lickrates-after-a-strategy-change"><i class="fa fa-check"></i><b>3.1.2</b> Lickrates after a strategy change</a></li>
<li class="chapter" data-level="3.1.3" data-path="acquisition.html"><a href="acquisition.html#group-analysis-of-behavioural-learning"><i class="fa fa-check"></i><b>3.1.3</b> Group analysis of behavioural learning</a></li>
<li class="chapter" data-level="3.1.4" data-path="acquisition.html"><a href="acquisition.html#course-of-learning"><i class="fa fa-check"></i><b>3.1.4</b> Course of learning</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="representation.html"><a href="representation.html"><i class="fa fa-check"></i><b>3.2</b> Representation</a><ul>
<li class="chapter" data-level="3.2.1" data-path="representation.html"><a href="representation.html#frequency-tuned-neurons-in-auditory-cortex"><i class="fa fa-check"></i><b>3.2.1</b> Frequency tuned neurons in auditory cortex</a></li>
<li class="chapter" data-level="3.2.2" data-path="representation.html"><a href="representation.html#sensorimotor-perturbations"><i class="fa fa-check"></i><b>3.2.2</b> Sensorimotor Perturbations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discussion.html"><a href="discussion.html"><i class="fa fa-check"></i><b>4</b> Discussion</a><ul>
<li class="chapter" data-level="4.1" data-path="behavioural-evidence-for-task-acquisition.html"><a href="behavioural-evidence-for-task-acquisition.html"><i class="fa fa-check"></i><b>4.1</b> Behavioural evidence for task acquisition</a></li>
<li class="chapter" data-level="4.2" data-path="auditory-cortex-represents-the-artificial-sensorimotor-contingency.html"><a href="auditory-cortex-represents-the-artificial-sensorimotor-contingency.html"><i class="fa fa-check"></i><b>4.2</b> Auditory cortex represents the artificial sensorimotor contingency</a></li>
<li class="chapter" data-level="4.3" data-path="implications-of-the-behavioural-and-neural-analysis.html"><a href="implications-of-the-behavioural-and-neural-analysis.html"><i class="fa fa-check"></i><b>4.3</b> Implications of the behavioural and neural analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="licking-behavior-of-all-mice.html"><a href="licking-behavior-of-all-mice.html"><i class="fa fa-check"></i><b>A</b> Licking behavior of all mice</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="implications-of-the-behavioural-and-neural-analysis" class="section level2">
<h2><span class="header-section-number">4.3</span> Implications of the behavioural and neural analysis</h2>
<p>Combined, behavioural and neuronal evidence suggests that it is possible to train head fixed mice on a behavioural task that is based on an artificial sensorimotor contingency, leading to a cortical representation of this contingency. From a computational perspective, such a task has important implications for general theories of sensorimotor learning and intelligence. Methodologically, the fact that this computationally rich task can be applied to head fixed mice means that its neural correlates can easily be studied using 2-photon imaging and other techniques that currently cannot be applied to freely moving animals.</p>
<p>As a next step, the behavioural data in the other animals will be analysed to determine whether they have learned the task. Furthermore, the representation of the contingency and the manner in which sensory and motor evidence are integrated will be investigated within the available neuronal dataset. Below, I will elaborate on how the collected data can be used for such investigations and propose extensions of the task paradigm that would shed light on questions that are currently not within reach.</p>
<p>In computational theories of intelligence, solving more complex tasks often involves a tradeoff between two important principles of learning.</p>
<p>On the one hand, by extracting statistical patterns from our environment, we learn about the information we should take into account to solve these tasks. This applies to sensory statistics as well as sensorimotor contingencies. The general smoothness of objects can be used to parse information at subneuronal <span class="citation">(Srinivasan et al., <a href="#ref-srinivasan1982pc">1982</a>)</span> and neuronal level <span class="citation">(Rao and Ballard, <a href="#ref-rao1999pc">1999</a>)</span>. This representation is apparent in all sensory modalities <span class="citation">(Fox and Wong, <a href="#ref-fox2005comparison">2005</a>; Smith and Lewicki, <a href="#ref-smith2006efficient">2006</a>)</span> and is sensitive to artificial manipulations of sensory statistics <span class="citation">(Wood, <a href="#ref-wood2016chick">2016</a>; Wood and Wood, <a href="#ref-wood2018chick">2018</a>)</span>. In a sensorimotor context, corollary discharges allow for sensory consequences of motor behaviour to be cancelled out. This is mediated, in part, by auditory cortex <span class="citation">(Schneider et al., <a href="#ref-schneider2014discharges">2014</a>)</span> and is sensitive to artificial contingencies, as well <span class="citation">(Schneider et al., <a href="#ref-schneider2018cortical">2018</a>)</span>.</p>
<p>On the other hand, the ultimate goal of neuronal processes is to generate appropriate behaviour. Following this perspective, the brain should gradually discard task-irrelevant information to optimize behavioural output. This idea is reflected in receptive fields in sensory cortex <span class="citation">(Hubel and Wiesel, <a href="#ref-hubel1965receptive">1965</a>, <a href="#ref-hubel1968receptive">1968</a>; Aertsen et al., <a href="#ref-aertsen1980receptive">1980</a>, <a href="#ref-aertsen1981receptive">1981</a>)</span>, which can reshape their properties according to task-relevance <span class="citation">(Fritz et al., <a href="#ref-fritz2003rapid">2003</a>)</span>, and extends to more complex tasks such as object recognition in the ventral stream <span class="citation">(DiCarlo et al., <a href="#ref-dicarlo2012visual">2012</a>)</span> and semantic development in humans <span class="citation">(Saxe et al., <a href="#ref-saxe2019semantic">2019</a>)</span>.</p>
<p>The presented task lies at the interface of these two theories. On the one hand, the goal of the task is ultimately to receive a reward in the form of water. On the other hand, this goal can more easily be reached by recognizing the sensorimotor contingency. Since neural data suggests that auditory cortex represents this contingency and this area is also involved in shaping behavioural learning, it appears likely that the animal’s behaviour is indeed not only driven by auditory associations, but in particular implements a contingency-driven behavioural policy.</p>
<p>Whether behavioural relevance has an impact on the extraction of sensorimotor contingencies in sensory cortex could be probed by making the rewards only contingent on the number of licks, leading the mice to explore the tonespace in any direction, without direct consequences on the likelihood of reward. This would connect the experiment more closely with the passive presentation of a novel sensorimotor contingency by <span class="citation">Schneider et al. (<a href="#ref-schneider2018cortical">2018</a>)</span>.</p>
<p>Neurons that are sensitive to pure sensorimotor perturbations are likely implicated in the integration of sensory and motor evidence. Both multisensory and sensorimotor integration processes in the brain are compatible with a Bayesian model and take the uncertainty associated with the different stimuli into account <span class="citation">(Wolpert et al., <a href="#ref-wolpert1995internal">1995</a>; Körding et al., <a href="#ref-kording2004force">2004</a>; Körding and Wolpert, <a href="#ref-kording2004bayesian">2004</a>; O’Reilly et al., <a href="#ref-oreilly2012bayesian">2012</a>)</span>. In order to test whether the contingency representation in auditory cortex was implicated in a similar mechanism of evidence integration, the sound levels were modulated on some sessions so as to present stimuli with different degrees of uncertainty. These level modulations can be used to probe the purpose of the perturbation-sensitive neurons. As an example, if the neuron in figure <a href="representation.html#fig:perturbation">1.8</a>b indeed represents a mixture of the presented and expected sound, the neuron’s tuning curve would be shifted closer to the expected rather than the presented sound for less certain, i. e. more silent auditory input. Extensions of this idea might manipulate precision of the auditory stimuli by increasing their bandwidth or presenting several stimuli at once.</p>
<p>Similarly to the neuronal representation, the existence of an internal model can be tested behaviourally by manipulating the precision of the provided information <span class="citation">(Wolpert et al., <a href="#ref-wolpert1995internal">1995</a>)</span>. This would allow for a behavioural examination of whether the mice take the sensorimotor contingency into account when solving the task. The neural evidence of a representation of the contingency in auditory cortex, an area that plays a role in behavioural learning, would suggest that this contingency can affect the mouse’s behaviour as well.</p>
<p>When freely moving rats were presented with a similar tonespace, recordings of the entorhinal-hippocampal circuit provided evidence for the emergence of grid cells representing this tonespace <span class="citation">(Aronov et al., <a href="#ref-aronov2017grid">2017</a>)</span>. Grid cells had initially been identified as a neural correlate of invariant spatial behaviour <span class="citation">(Hafting et al., <a href="#ref-hafting2005grid">2005</a>)</span>. More recently, they have also been implicated in non-spatial cognitive tasks <span class="citation">(Constantinescu et al., <a href="#ref-constantinescu2016grid">2016</a>)</span>, which provides support for the hypothesis that conceptual knowledge is organized in ‘cognitive maps’ <span class="citation">(Tolman, <a href="#ref-tolman1948map">1948</a>)</span>. The emergence of grid cells in this behavioural task could be tested by determining the anatomical connections of the neurons representing sensorimotor perturbations and subsequently imaging entorhinal cortex in behaving mice <span class="citation">(Low et al., <a href="#ref-low2014entorhinal">2014</a>)</span>. Furthermore, grid cells generate a particularly precise error-correcting code compared to classical population codes in sensory cortex <span class="citation">(Sreenivasan and Fiete, <a href="#ref-sreenivasan2011grid">2011</a>)</span>. A better understanding of the representation of sensorimotor perturbations, which require such an error correction, might therefore shed light on the emergence of conceptual grid cells as well.</p>
<p>For the purpose of dissecting the circuit mediating this potential contingency representation, it would also be important to image inhibitory neurons in auditory cortex, as the proposed mechanism would involve cancelling out predictions from another cortical area <span class="citation">(Larkum et al., <a href="#ref-larkum1999inhibition">1999</a>)</span>.</p>
<p>In conclusion, this dissertation presented a new behavioural task for head-fixed mice involving the learning of a novel, continuous auditory sensorimotor contingency. Mice were able to learn this task, and neural data suggest that auditory cortex can represent the corresponding contingency. As a next step, the variations in the collected data will allow for a more detailed examination of the implemented behavioural policy, the representation of the contingency, and the manner by which the sensory and motor evidence is integrated to guide behaviour. Furthermore, variations of the task would allow for an examination of the influence of behavioural relevance on the possible emergence of an abstract tonespace, connecting a simple task in head fixed mice to some of the most debated computational theories of learning.</p>

</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-srinivasan1982pc">
<p>Srinivasan MV, Laughlin SB, Dubs A (1982) Predictive Coding: A Fresh View of Inhibition in the Retina. Proceedings of the Royal Society of London Series B, Biological Sciences 216:427–459 Available at: <a href="http://www.jstor.org/stable/35861">http://www.jstor.org/stable/35861</a>.</p>
</div>
<div id="ref-rao1999pc">
<p>Rao RPN, Ballard DH (1999) Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nature Neuroscience 2:79–87 Available at: <a href="http://www.nature.com/articles/nn0199{\_}79">http://www.nature.com/articles/nn0199{\_}79</a>.</p>
</div>
<div id="ref-fox2005comparison">
<p>Fox K, Wong ROL (2005) A comparison of experience-dependent plasticity in the visual and somatosensory systems. Neuron 48:465–477.</p>
</div>
<div id="ref-smith2006efficient">
<p>Smith EC, Lewicki MS (2006) Efficient auditory coding. Nature 439:978.</p>
</div>
<div id="ref-wood2016chick">
<p>Wood JN (2016) A smoothness constraint on the development of object recognition. Cognition 153:140–145 Available at: <a href="https://www.sciencedirect.com/science/article/pii/S0010027716301019?via{\%}3Dihub">https://www.sciencedirect.com/science/article/pii/S0010027716301019?via{\%}3Dihub</a>.</p>
</div>
<div id="ref-wood2018chick">
<p>Wood JN, Wood SM (2018) The Development of Invariant Object Recognition Requires Visual Experience With Temporally Smooth Objects. Cognitive Science 42:1391–1406 Available at: <a href="http://doi.wiley.com/10.1111/cogs.12595">http://doi.wiley.com/10.1111/cogs.12595</a>.</p>
</div>
<div id="ref-schneider2014discharges">
<p>Schneider DM, Nelson A, Mooney R (2014) A synaptic and circuit basis for corollary discharge in the auditory cortex. Nature 513:189–194 Available at: <a href="http://www.nature.com/articles/nature13724">http://www.nature.com/articles/nature13724</a>.</p>
</div>
<div id="ref-schneider2018cortical">
<p>Schneider DM, Sundararajan J, Mooney R (2018) A cortical filter that learns to suppress the acoustic consequences of movement. Nature 561:391–395 Available at: <a href="http://www.nature.com/articles/s41586-018-0520-5">http://www.nature.com/articles/s41586-018-0520-5</a>.</p>
</div>
<div id="ref-hubel1965receptive">
<p>Hubel DH, Wiesel TN (1965) Receptive Fields and Functional Architecture in Two Nonstriate Visual Areas (18 and 19) of the Cat. Journal of neurophysiology 28:229–289 Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/14283058">http://www.ncbi.nlm.nih.gov/pubmed/14283058</a>.</p>
</div>
<div id="ref-hubel1968receptive">
<p>Hubel DH, Wiesel TN (1968) Receptive fields and functional architecture of monkey striate cortex. The Journal of Physiology 195:215–243 Available at: <a href="http://doi.wiley.com/10.1113/jphysiol.1968.sp008455">http://doi.wiley.com/10.1113/jphysiol.1968.sp008455</a>.</p>
</div>
<div id="ref-aertsen1980receptive">
<p>Aertsen AMHJ, Johannesma PIM, Hermes DJ (1980) Spectro-temporal receptive fields of auditory neurons in the grassfrog. Biological Cybernetics 38:235–248 Available at: <a href="http://link.springer.com/10.1007/BF00337016">http://link.springer.com/10.1007/BF00337016</a>.</p>
</div>
<div id="ref-aertsen1981receptive">
<p>Aertsen AM, Olders JH, Johannesma PI (1981) Spectro-temporal receptive fields of auditory neurons in the grassfrog. III. Analysis of the stimulus-event relation for natural stimuli. Biological cybernetics 39:195–209 Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/6972785">http://www.ncbi.nlm.nih.gov/pubmed/6972785</a>.</p>
</div>
<div id="ref-fritz2003rapid">
<p>Fritz J, Shamma S, Elhilali M, Klein D (2003) Rapid task-related plasticity of spectrotemporal receptive fields in primary auditory cortex. Nature Neuroscience 6:1216–1223 Available at: <a href="http://www.nature.com/articles/nn1141">http://www.nature.com/articles/nn1141</a>.</p>
</div>
<div id="ref-dicarlo2012visual">
<p>DiCarlo JJ, Zoccolan D, Rust NC (2012) How does the brain solve visual object recognition? Neuron 73:415–434 Available at: <a href="http://dx.doi.org/10.1016/j.neuron.2012.01.010">http://dx.doi.org/10.1016/j.neuron.2012.01.010</a>.</p>
</div>
<div id="ref-saxe2019semantic">
<p>Saxe AM, McClelland JL, Ganguli S (2019) A mathematical theory of semantic development in deep neural networks. Proceedings of the National Academy of Sciences of the United States of America 116:11537–11546 Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/31101713 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6561300">http://www.ncbi.nlm.nih.gov/pubmed/31101713 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC6561300</a>.</p>
</div>
<div id="ref-wolpert1995internal">
<p>Wolpert D, Ghahramani Z, Jordan M (1995) An internal model for sensorimotor integration. Science 269:1880–1882 Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/7569931 http://www.sciencemag.org/cgi/doi/10.1126/science.7569931">http://www.ncbi.nlm.nih.gov/pubmed/7569931 http://www.sciencemag.org/cgi/doi/10.1126/science.7569931</a>.</p>
</div>
<div id="ref-kording2004force">
<p>Körding KP, Ku S-p, Wolpert DM (2004) Bayesian Integration in Force Estimation. Journal of Neurophysiology 92:3161–3165 Available at: <a href="http://www.physiology.org/doi/10.1152/jn.00275.2004">http://www.physiology.org/doi/10.1152/jn.00275.2004</a>.</p>
</div>
<div id="ref-kording2004bayesian">
<p>Körding KP, Wolpert DM (2004) Bayesian integration in sensorimotor learning. Nature 427:244–247 Available at: <a href="http://www.nature.com/articles/nature02169">http://www.nature.com/articles/nature02169</a>.</p>
</div>
<div id="ref-oreilly2012bayesian">
<p>O’Reilly JX, Jbabdi S, Behrens TEJ (2012) How can a Bayesian approach inform neuroscience? European Journal of Neuroscience 35:1169–1179 Available at: <a href="http://doi.wiley.com/10.1111/j.1460-9568.2012.08010.x">http://doi.wiley.com/10.1111/j.1460-9568.2012.08010.x</a>.</p>
</div>
<div id="ref-aronov2017grid">
<p>Aronov D, Nevers R, Tank DW (2017) Mapping of a non-spatial dimension by the hippocampal–entorhinal circuit. Nature 543:719–722 Available at: <a href="http://www.nature.com/articles/nature21692">http://www.nature.com/articles/nature21692</a>.</p>
</div>
<div id="ref-hafting2005grid">
<p>Hafting T, Fyhn M, Molden S, Moser M-B, Moser EI (2005) Microstructure of a spatial map in the entorhinal cortex. Nature 436:801–806 Available at: <a href="https://www.nature.com/articles/nature03721">https://www.nature.com/articles/nature03721</a>.</p>
</div>
<div id="ref-constantinescu2016grid">
<p>Constantinescu AO, O’Reilly JX, Behrens TEJ (2016) Organizing conceptual knowledge in humans with a gridlike code. Science (New York, NY) 352:1464–1468 Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/27313047 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5248972">http://www.ncbi.nlm.nih.gov/pubmed/27313047 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5248972</a>.</p>
</div>
<div id="ref-tolman1948map">
<p>Tolman EC (1948) Cognitive maps in rats and men. Psychological review 55:189–208 Available at: <a href="https://psycnet.apa.org/record/1949-00103-001 http://www.ncbi.nlm.nih.gov/pubmed/9230435">https://psycnet.apa.org/record/1949-00103-001 http://www.ncbi.nlm.nih.gov/pubmed/9230435</a>.</p>
</div>
<div id="ref-low2014entorhinal">
<p>Low RJ, Gu Y, Tank DW (2014) Cellular resolution optical access to brain regions in fissures: imaging medial prefrontal cortex and grid cells in entorhinal cortex. Proceedings of the National Academy of Sciences of the United States of America 111:18739–18744 Available at: <a href="http://www.ncbi.nlm.nih.gov/pubmed/25503366 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4284609">http://www.ncbi.nlm.nih.gov/pubmed/25503366 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4284609</a>.</p>
</div>
<div id="ref-sreenivasan2011grid">
<p>Sreenivasan S, Fiete I (2011) Grid cells generate an analog error-correcting code for singularly precise neural computation. Nature Neuroscience 14:1330–1337 Available at: <a href="http://www.nature.com/articles/nn.2901">http://www.nature.com/articles/nn.2901</a>.</p>
</div>
<div id="ref-larkum1999inhibition">
<p>Larkum ME, Zhu JJ, Sakmann B (1999) A new cellular mechanism for coupling inputs arriving at different cortical layers. Nature 398:338–341 Available at: <a href="http://www.nature.com/articles/18686">http://www.nature.com/articles/18686</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="auditory-cortex-represents-the-artificial-sensorimotor-contingency.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": ["thesis-tt-19.pdf", "thesis-tt-19.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
